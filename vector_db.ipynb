{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef0973e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing schema file: schemas\\chinook_db.py\n",
      "Processing schema file: schemas\\netflix_db.py\n",
      "Added 117 documents to the vector database\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from typing import Dict, List, Any\n",
    "from pathlib import Path\n",
    "import importlib.util\n",
    "\n",
    "class SchemaVectorDB:\n",
    "    def __init__(self, db_path: str = \"./chroma_db\"):\n",
    "        \"\"\"Initialize the ChromaDB client and collection\"\"\"\n",
    "        self.client = chromadb.PersistentClient(path=db_path)\n",
    "        self.collection = self.client.get_or_create_collection(\n",
    "            name=\"schema_collection\",\n",
    "            metadata={\"hnsw:space\": \"cosine\"}\n",
    "        )\n",
    "        \n",
    "    def load_schema_from_file(self, file_path: str) -> Dict[str, Any]:\n",
    "        \"\"\"Load schema from a Python file\"\"\"\n",
    "        try:\n",
    "            spec = importlib.util.spec_from_file_location(\"schema_module\", file_path)\n",
    "            schema_module = importlib.util.module_from_spec(spec)\n",
    "            spec.loader.exec_module(schema_module)\n",
    "            return schema_module.schema\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading schema from {file_path}: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def create_embeddings_from_schema(self, schema: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Create embedding documents from schema structure\"\"\"\n",
    "        documents = []\n",
    "        \n",
    "        for table_name, table_info in schema.items():\n",
    "            # Convert columns list to a comma-separated string for metadata\n",
    "            columns = table_info.get(\"columns\", {})\n",
    "            columns_str = \", \".join(columns.keys()) if columns else \"\"\n",
    "            \n",
    "            # Create table-level document\n",
    "            table_doc = {\n",
    "                \"id\": f\"table_{table_name}\",\n",
    "                \"type\": \"table\",\n",
    "                \"table_name\": table_name,\n",
    "                \"description\": table_info.get(\"description\", \"\"),\n",
    "                \"columns\": columns_str,  # Store as string instead of list\n",
    "                \"text\": f\"Table: {table_name}. Description: {table_info.get('description', '')}. Columns: {columns_str}\"\n",
    "            }\n",
    "            documents.append(table_doc)\n",
    "            \n",
    "            # Create column-level documents\n",
    "            for col_name, col_type in columns.items():\n",
    "                col_doc = {\n",
    "                    \"id\": f\"column_{table_name}_{col_name}\",\n",
    "                    \"type\": \"column\",\n",
    "                    \"table_name\": table_name,\n",
    "                    \"column_name\": col_name,\n",
    "                    \"column_type\": col_type,\n",
    "                    \"table_description\": table_info.get(\"description\", \"\"),\n",
    "                    \"text\": f\"Column: {col_name} (Type: {col_type}) in table {table_name}. Table description: {table_info.get('description', '')}\"\n",
    "                }\n",
    "                documents.append(col_doc)\n",
    "        \n",
    "        return documents\n",
    "    \n",
    "    def populate_database(self, schemas_folder: str):\n",
    "        \"\"\"Populate the vector database with schema information\"\"\"\n",
    "        schemas_path = Path(schemas_folder)\n",
    "        \n",
    "        # Clear existing collection\n",
    "        self.client.delete_collection(\"schema_collection\")\n",
    "        self.collection = self.client.create_collection(\n",
    "            name=\"schema_collection\",\n",
    "            metadata={\"hnsw:space\": \"cosine\"}\n",
    "        )\n",
    "        \n",
    "        all_documents = []\n",
    "        \n",
    "        # Process each schema file\n",
    "        for file_path in schemas_path.glob(\"*.py\"):\n",
    "            if file_path.name.startswith(\"__\"):\n",
    "                continue\n",
    "                \n",
    "            print(f\"Processing schema file: {file_path}\")\n",
    "            schema = self.load_schema_from_file(str(file_path))\n",
    "            \n",
    "            if schema:\n",
    "                documents = self.create_embeddings_from_schema(schema)\n",
    "                all_documents.extend(documents)\n",
    "        \n",
    "        if all_documents:\n",
    "            # Add to ChromaDB\n",
    "            ids = [doc[\"id\"] for doc in all_documents]\n",
    "            texts = [doc[\"text\"] for doc in all_documents]\n",
    "            metadatas = [{k: v for k, v in doc.items() if k not in [\"id\", \"text\"]} \n",
    "                        for doc in all_documents]\n",
    "            \n",
    "            self.collection.add(\n",
    "                documents=texts,\n",
    "                metadatas=metadatas,\n",
    "                ids=ids\n",
    "            )\n",
    "            \n",
    "            print(f\"Added {len(all_documents)} documents to the vector database\")\n",
    "        \n",
    "    def query_relevant_tables(self, user_query: str, n_results: int = 10) -> Dict[str, Any]:\n",
    "        \"\"\"Query the vector database to find relevant tables and columns\"\"\"\n",
    "        \n",
    "        # Query the collection\n",
    "        results = self.collection.query(\n",
    "            query_texts=[user_query],\n",
    "            n_results=n_results\n",
    "        )\n",
    "        \n",
    "        # Process results to group by tables\n",
    "        table_recommendations = {}\n",
    "        column_recommendations = {}\n",
    "        \n",
    "        if results['documents'] and results['documents'][0]:\n",
    "            for i, metadata in enumerate(results['metadatas'][0]):\n",
    "                distance = results['distances'][0][i]\n",
    "                \n",
    "                if metadata['type'] == 'table':\n",
    "                    table_name = metadata['table_name']\n",
    "                    # Convert columns string back to list for consistency\n",
    "                    columns_list = [col.strip() for col in metadata['columns'].split(\",\") if col.strip()]\n",
    "                    table_recommendations[table_name] = {\n",
    "                        'description': metadata['description'],\n",
    "                        'columns': columns_list,\n",
    "                        'relevance_score': 1 - distance\n",
    "                    }\n",
    "                \n",
    "                elif metadata['type'] == 'column':\n",
    "                    table_name = metadata['table_name']\n",
    "                    column_name = metadata['column_name']\n",
    "                    \n",
    "                    if table_name not in column_recommendations:\n",
    "                        column_recommendations[table_name] = {\n",
    "                            'description': metadata['table_description'],\n",
    "                            'columns': {}\n",
    "                        }\n",
    "                    \n",
    "                    column_recommendations[table_name]['columns'][column_name] = {\n",
    "                        'type': metadata['column_type'],\n",
    "                        'relevance_score': 1 - distance\n",
    "                    }\n",
    "        \n",
    "        return {\n",
    "            'query': user_query,\n",
    "            'table_recommendations': table_recommendations,\n",
    "            'column_recommendations': column_recommendations\n",
    "        }\n",
    "    \n",
    "    def get_recommendations(self, user_query: str, top_tables: int = 3) -> Dict[str, Any]:\n",
    "        \"\"\"Get formatted recommendations for tables and columns\"\"\"\n",
    "        \n",
    "        results = self.query_relevant_tables(user_query, n_results=20)\n",
    "        \n",
    "        # Combine and rank tables\n",
    "        all_tables = {}\n",
    "        \n",
    "        # Add table-level recommendations\n",
    "        for table_name, info in results['table_recommendations'].items():\n",
    "            all_tables[table_name] = {\n",
    "                'description': info['description'],\n",
    "                'all_columns': info['columns'],\n",
    "                'relevant_columns': {},\n",
    "                'table_score': info['relevance_score'],\n",
    "                'column_score': 0\n",
    "            }\n",
    "        \n",
    "        # Add column-level recommendations\n",
    "        for table_name, info in results['column_recommendations'].items():\n",
    "            if table_name not in all_tables:\n",
    "                all_tables[table_name] = {\n",
    "                    'description': info['description'],\n",
    "                    'all_columns': [],\n",
    "                    'relevant_columns': {},\n",
    "                    'table_score': 0,\n",
    "                    'column_score': 0\n",
    "                }\n",
    "            \n",
    "            all_tables[table_name]['relevant_columns'] = info['columns']\n",
    "            \n",
    "            # Calculate average column score\n",
    "            if info['columns']:\n",
    "                avg_score = sum(col['relevance_score'] for col in info['columns'].values()) / len(info['columns'])\n",
    "                all_tables[table_name]['column_score'] = avg_score\n",
    "        \n",
    "        # Calculate combined score and sort\n",
    "        for table_name in all_tables:\n",
    "            table_info = all_tables[table_name]\n",
    "            # Weighted combination of table and column scores\n",
    "            combined_score = (table_info['table_score'] * 0.3) + (table_info['column_score'] * 0.7)\n",
    "            table_info['combined_score'] = combined_score\n",
    "        \n",
    "        # Sort by combined score\n",
    "        sorted_tables = sorted(all_tables.items(), key=lambda x: x[1]['combined_score'], reverse=True)\n",
    "        \n",
    "        # Format response\n",
    "        recommendations = {\n",
    "            'query': user_query,\n",
    "            'recommended_tables': []\n",
    "        }\n",
    "        \n",
    "        for table_name, info in sorted_tables[:top_tables]:\n",
    "            table_rec = {\n",
    "                'table_name': table_name,\n",
    "                'description': info['description'],\n",
    "                'relevance_score': round(info['combined_score'], 3),\n",
    "                'recommended_columns': []\n",
    "            }\n",
    "            \n",
    "            # Sort columns by relevance score\n",
    "            if info['relevant_columns']:\n",
    "                sorted_columns = sorted(info['relevant_columns'].items(), \n",
    "                                      key=lambda x: x[1]['relevance_score'], reverse=True)\n",
    "                \n",
    "                for col_name, col_info in sorted_columns:\n",
    "                    table_rec['recommended_columns'].append({\n",
    "                        'column_name': col_name,\n",
    "                        'column_type': col_info['type'],\n",
    "                        'relevance_score': round(col_info['relevance_score'], 3)\n",
    "                    })\n",
    "            \n",
    "            recommendations['recommended_tables'].append(table_rec)\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "\n",
    "vector_db = SchemaVectorDB()\n",
    "    \n",
    "    # Populate the database with schemas from the folder\n",
    "schemas_folder = \"./schemas\"  # Update this path to your schemas folder\n",
    "vector_db.populate_database(schemas_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e398c113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SCHEMA RECOMMENDATION SYSTEM - TEST RESULTS\n",
      "================================================================================\n",
      "\n",
      "Query: Give me track in pop genre\n",
      "--------------------------------------------------\n",
      "\n",
      "Table: PlaylistTrack (Score: 0.366)\n",
      "Description: This table records the association between playlists and tracks, linking each track to the playlists it belongs to. It supports the organization and management of music collections by enabling the construction of playlists from individual tracks within a music application.\n",
      "Recommended columns:\n",
      "  - TrackId (INTEGER) - Score: 0.373\n",
      "  - PlaylistId (INTEGER) - Score: 0.345\n",
      "\n",
      "\n",
      "Table: Track (Score: 0.365)\n",
      "Description: This table holds detailed information about individual music tracks, including their titles, associated album, media type, genre, composer, duration, file size, and unit price. It serves as a central repository for cataloging and managing music inventory, supporting media libraries, sales transactions, and music discovery features within the application.\n",
      "Recommended columns:\n",
      "  - GenreId (INTEGER) - Score: 0.44\n",
      "  - TrackId (INTEGER) - Score: 0.395\n",
      "  - MediaTypeId (INTEGER) - Score: 0.348\n",
      "  - AlbumId (INTEGER) - Score: 0.344\n",
      "  - Milliseconds (INTEGER) - Score: 0.341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_queries = [\n",
    "        \"Give me track in pop genre\"\n",
    "    ]\n",
    "    \n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SCHEMA RECOMMENDATION SYSTEM - TEST RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(\"-\" * 50)\n",
    "        \n",
    "recommendations = vector_db.get_recommendations(query, top_tables=2)\n",
    "        \n",
    "for table_rec in recommendations['recommended_tables']:\n",
    "    print(f\"\\nTable: {table_rec['table_name']} (Score: {table_rec['relevance_score']})\")\n",
    "    print(f\"Description: {table_rec['description']}\")\n",
    "            \n",
    "    if table_rec['recommended_columns']: print(\"Recommended columns:\")\n",
    "    \n",
    "    for col in table_rec['recommended_columns'][:5]:  # Show top 5 columns\n",
    "        print(f\"  - {col['column_name']} ({col['column_type']}) - Score: {col['relevance_score']}\")\n",
    "            \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a6d7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

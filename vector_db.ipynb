{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0973e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "import importlib.util\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "class VectorDatabaseMapper:\n",
    "    \"\"\"\n",
    "    Vector database system using ChromaDB for mapping user prompts to relevant database tables and columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2', collection_name='schema_embeddings'):\n",
    "        \"\"\"\n",
    "        Initialize the vector database mapper with ChromaDB.\n",
    "        \n",
    "        Args:\n",
    "            model_name (str): Name of the sentence transformer model to use\n",
    "            collection_name (str): Name of the ChromaDB collection\n",
    "        \"\"\"\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "        self.embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=model_name)\n",
    "        self.collection = self.client.get_or_create_collection(\n",
    "            name=collection_name,\n",
    "            embedding_function=self.embedding_function\n",
    "        )\n",
    "        self.schema_metadata = {}\n",
    "        \n",
    "    def load_schema_from_file(self, schema_file_path: str) -> Dict:\n",
    "        \"\"\"Load schema from a Python file.\"\"\"\n",
    "        try:\n",
    "            spec = importlib.util.spec_from_file_location(\"schema_module\", schema_file_path)\n",
    "            schema_module = importlib.util.module_from_spec(spec)\n",
    "            spec.loader.exec_module(schema_module)\n",
    "            return schema_module.schema\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading schema from {schema_file_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def generate_text_descriptions(self, schema: Dict, db_name: str) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Generate natural language descriptions for tables and columns.\n",
    "        \n",
    "        Args:\n",
    "            schema (dict): Database schema\n",
    "            db_name (str): Database name\n",
    "            \n",
    "        Returns:\n",
    "            List[Dict]: List of text descriptions with metadata\n",
    "        \"\"\"\n",
    "        descriptions = []\n",
    "        \n",
    "        for table_name, table_info in schema.items():\n",
    "            # Handle both old and new schema formats\n",
    "            if isinstance(table_info, dict) and 'columns' in table_info:\n",
    "                columns = table_info['columns']\n",
    "                sample_data = table_info.get('sample', [])\n",
    "            else:\n",
    "                columns = table_info\n",
    "                sample_data = []\n",
    "            \n",
    "            # Generate table-level description\n",
    "            column_names = []\n",
    "            for col_info in columns:\n",
    "                if isinstance(col_info, dict):\n",
    "                    column_names.extend(col_info.keys())\n",
    "                else:\n",
    "                    column_names.append(str(col_info))\n",
    "            \n",
    "            table_description = f\"Table {table_name} contains information about {self._infer_table_purpose(table_name, column_names)}. \"\n",
    "            table_description += f\"It has columns: {', '.join(column_names)}.\"\n",
    "            \n",
    "            # Add sample data context if available\n",
    "            if sample_data:\n",
    "                sample_values = []\n",
    "                for sample in sample_data[:2]:\n",
    "                    for key, value in sample.items():\n",
    "                        if value is not None:\n",
    "                            sample_values.append(f\"{key}: {value}\")\n",
    "                \n",
    "                if sample_values:\n",
    "                    table_description += f\" Example data includes: {'; '.join(sample_values[:5])}.\"\n",
    "            \n",
    "            descriptions.append({\n",
    "                'text': table_description,\n",
    "                'type': 'table',\n",
    "                'database': db_name,\n",
    "                'table': table_name,\n",
    "                'column': None,\n",
    "                'metadata': {\n",
    "                    'column_count': len(columns),\n",
    "                    'has_samples': len(sample_data) > 0\n",
    "                }\n",
    "            })\n",
    "            \n",
    "            # Generate column-level descriptions\n",
    "            for col_info in columns:\n",
    "                if isinstance(col_info, dict):\n",
    "                    for col_name, col_type in col_info.items():\n",
    "                        col_description = f\"Column {col_name} in table {table_name} is of type {col_type}. \"\n",
    "                        col_description += self._infer_column_purpose(col_name, col_type, table_name)\n",
    "                        \n",
    "                        if sample_data:\n",
    "                            sample_values = [str(sample.get(col_name, '')) for sample in sample_data if sample.get(col_name) is not None]\n",
    "                            if sample_values:\n",
    "                                col_description += f\" Example values: {', '.join(sample_values[:3])}.\"\n",
    "                        \n",
    "                        descriptions.append({\n",
    "                            'text': col_description,\n",
    "                            'type': 'column',\n",
    "                            'database': db_name,\n",
    "                            'table': table_name,\n",
    "                            'column': col_name,\n",
    "                            'metadata': {\n",
    "                                'data_type': col_type,\n",
    "                                'has_samples': len(sample_data) > 0\n",
    "                            }\n",
    "                        })\n",
    "        \n",
    "        return descriptions\n",
    "    \n",
    "    def _infer_table_purpose(self, table_name: str, column_names: List[str]) -> str:\n",
    "        \"\"\"Infer the purpose of a table based on its name and columns.\"\"\"\n",
    "        table_lower = table_name.lower()\n",
    "        cols_lower = [col.lower() for col in column_names]\n",
    "        \n",
    "        if 'user' in table_lower or 'customer' in table_lower:\n",
    "            return \"users or customers\"\n",
    "        elif 'order' in table_lower or 'purchase' in table_lower:\n",
    "            return \"orders or purchases\"\n",
    "        elif 'product' in table_lower or 'item' in table_lower:\n",
    "            return \"products or items\"\n",
    "        elif 'payment' in table_lower or 'transaction' in table_lower:\n",
    "            return \"payments or transactions\"\n",
    "        elif 'employee' in table_lower or 'staff' in table_lower:\n",
    "            return \"employees or staff\"\n",
    "        elif 'track' in table_lower or 'song' in table_lower:\n",
    "            return \"music tracks or songs\"\n",
    "        elif 'album' in table_lower:\n",
    "            return \"music albums\"\n",
    "        elif 'artist' in table_lower:\n",
    "            return \"artists or musicians\"\n",
    "        elif 'genre' in table_lower:\n",
    "            return \"music genres\"\n",
    "        elif 'invoice' in table_lower:\n",
    "            return \"invoices or billing\"\n",
    "        elif 'playlist' in table_lower:\n",
    "            return \"playlists\"\n",
    "        else:\n",
    "            return f\"{table_name.replace('_', ' ')}\"\n",
    "    \n",
    "    def _infer_column_purpose(self, col_name: str, col_type: str, table_name: str) -> str:\n",
    "        \"\"\"Infer the purpose of a column based on its name and type.\"\"\"\n",
    "        col_lower = col_name.lower()\n",
    "        \n",
    "        if 'id' in col_lower:\n",
    "            return f\"It serves as an identifier for {table_name}.\"\n",
    "        elif 'name' in col_lower:\n",
    "            return \"It stores name information.\"\n",
    "        elif 'email' in col_lower:\n",
    "            return \"It stores email addresses.\"\n",
    "        elif 'phone' in col_lower:\n",
    "            return \"It stores phone numbers.\"\n",
    "        elif 'address' in col_lower:\n",
    "            return \"It stores address information.\"\n",
    "        elif 'date' in col_lower or 'time' in col_lower:\n",
    "            return \"It stores date/time information.\"\n",
    "        elif 'price' in col_lower or 'amount' in col_lower or 'cost' in col_lower:\n",
    "            return \"It stores monetary values.\"\n",
    "        elif 'quantity' in col_lower or 'count' in col_lower:\n",
    "            return \"It stores quantity or count information.\"\n",
    "        elif 'description' in col_lower:\n",
    "            return \"It stores descriptive text.\"\n",
    "        elif 'status' in col_lower:\n",
    "            return \"It stores status information.\"\n",
    "        else:\n",
    "            return f\"It stores {col_name.replace('_', ' ').lower()} data.\"\n",
    "    \n",
    "    def build_vector_database(self, schema_folder: str = \"schemas\") -> None:\n",
    "        \"\"\"\n",
    "        Build ChromaDB vector database from schema files.\n",
    "        \n",
    "        Args:\n",
    "            schema_folder (str): Path to folder containing schema files\n",
    "        \"\"\"\n",
    "        print(\"Building ChromaDB vector database...\")\n",
    "        \n",
    "        schema_files = list(Path(schema_folder).glob(\"*.py\"))\n",
    "        \n",
    "        if not schema_files:\n",
    "            print(f\"No schema files found in {schema_folder}\")\n",
    "            return\n",
    "        \n",
    "        all_descriptions = []\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents = []\n",
    "        \n",
    "        for schema_file in schema_files:\n",
    "            db_name = schema_file.stem\n",
    "            if db_name.endswith('_db'):\n",
    "                db_name = db_name[:-3]\n",
    "            \n",
    "            print(f\"Processing schema: {schema_file.name}\")\n",
    "            \n",
    "            schema = self.load_schema_from_file(str(schema_file))\n",
    "            if not schema:\n",
    "                continue\n",
    "            \n",
    "            descriptions = self.generate_text_descriptions(schema, db_name)\n",
    "            all_descriptions.extend(descriptions)\n",
    "        \n",
    "        for i, desc in enumerate(all_descriptions):\n",
    "            ids.append(f\"desc_{i}\")\n",
    "            documents.append(desc['text'])\n",
    "            metadatas.append({\n",
    "                'type': desc['type'],\n",
    "                'database': desc['database'],\n",
    "                'table': desc['table'],\n",
    "                'column': desc['column'],\n",
    "                'metadata': json.dumps(desc['metadata'])\n",
    "            })\n",
    "        \n",
    "        print(f\"Generated {len(all_descriptions)} descriptions\")\n",
    "        \n",
    "        # Clear existing collection and add new embeddings\n",
    "        self.collection.delete()\n",
    "        if documents:\n",
    "            self.collection.add(\n",
    "                documents=documents,\n",
    "                metadatas=metadatas,\n",
    "                ids=ids\n",
    "            )\n",
    "        \n",
    "        self.schema_metadata = all_descriptions\n",
    "        print(f\"ChromaDB vector database built with {len(all_descriptions)} entries\")\n",
    "    \n",
    "    def find_relevant_schema(self, user_prompt: str, top_k: int = 10) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Find the most relevant tables and columns for a user prompt using ChromaDB.\n",
    "        \n",
    "        Args:\n",
    "            user_prompt (str): User's natural language query\n",
    "            top_k (int): Number of top results to return\n",
    "            \n",
    "        Returns:\n",
    "            List[Dict]: Ranked list of relevant schema elements\n",
    "        \"\"\"\n",
    "        results = self.collection.query(\n",
    "            query_texts=[user_prompt],\n",
    "            n_results=top_k\n",
    "        )\n",
    "        \n",
    "        relevant_schema = []\n",
    "        for i in range(len(results['ids'][0])):\n",
    "            metadata = results['metadatas'][0][i]\n",
    "            relevant_schema.append({\n",
    "                'text': results['documents'][0][i],\n",
    "                'type': metadata['type'],\n",
    "                'database': metadata['database'],\n",
    "                'table': metadata['table'],\n",
    "                'column': metadata['column'],\n",
    "                'similarity_score': results['distances'][0][i],\n",
    "                'metadata': json.loads(metadata['metadata'])\n",
    "            })\n",
    "        \n",
    "        return relevant_schema\n",
    "    \n",
    "    def get_relevant_tables_columns(self, user_prompt: str, top_k: int = 5) -> Dict:\n",
    "        \"\"\"\n",
    "        Get relevant tables and columns for a user prompt.\n",
    "        \n",
    "        Args:\n",
    "            user_prompt (str): User's natural language query\n",
    "            top_k (int): Number of top results to consider\n",
    "            \n",
    "        Returns:\n",
    "            Dict: Structured context with tables and columns\n",
    "        \"\"\"\n",
    "        relevant_schema = self.find_relevant_schema(user_prompt, top_k)\n",
    "        \n",
    "        if not relevant_schema:\n",
    "            return {}\n",
    "        \n",
    "        context = {}\n",
    "        \n",
    "        for item in relevant_schema:\n",
    "            db_name = item['database']\n",
    "            table_name = item['table']\n",
    "            \n",
    "            if db_name not in context:\n",
    "                context[db_name] = {}\n",
    "            \n",
    "            if table_name not in context[db_name]:\n",
    "                context[db_name][table_name] = {\n",
    "                    'columns': [],\n",
    "                    'relevance_score': 0,\n",
    "                    'description': ''\n",
    "                }\n",
    "            \n",
    "            if item['type'] == 'table':\n",
    "                context[db_name][table_name]['description'] = item['text']\n",
    "                context[db_name][table_name]['relevance_score'] = max(\n",
    "                    context[db_name][table_name]['relevance_score'],\n",
    "                    1.0 - item['similarity_score']  # Convert distance to similarity\n",
    "                )\n",
    "            elif item['type'] == 'column':\n",
    "                context[db_name][table_name]['columns'].append({\n",
    "                    'name': item['column'],\n",
    "                    'description': item['text'],\n",
    "                    'relevance_score': 1.0 - item['similarity_score'],\n",
    "                    'data_type': item['metadata'].get('data_type', 'UNKNOWN')\n",
    "                })\n",
    "        \n",
    "        # Sort columns by relevance\n",
    "        for db_name in context:\n",
    "            for table_name in context[db_name]:\n",
    "                context[db_name][table_name]['columns'].sort(\n",
    "                    key=lambda x: x['relevance_score'], \n",
    "                    reverse=True\n",
    "                )\n",
    "        \n",
    "        return context\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize vector database\n",
    "    vector_db = VectorDatabaseMapper()\n",
    "    \n",
    "    # Build vector database from schema files\n",
    "    vector_db.build_vector_database(\"schemas\")\n",
    "    \n",
    "    # Example queries\n",
    "    test_queries = [\n",
    "        \"Show me all the artists and their names\",\n",
    "        \"How many tracks are there in the database?\",\n",
    "        \"What is the total sales amount?\",\n",
    "        \"List all customers from USA\",\n",
    "        \"Find the most expensive album\",\n",
    "        \"Group sales by country\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TESTING CHROMADB VECTOR MAPPING\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Get relevant tables and columns\n",
    "        context = vector_db.get_relevant_tables_columns(query)\n",
    "        \n",
    "        if context:\n",
    "            for db_name, tables in context.items():\n",
    "                print(f\"Database: {db_name}\")\n",
    "                for table_name, table_info in tables.items():\n",
    "                    print(f\"Table: {table_name} (Relevance: {table_info['relevance_score']:.3f})\")\n",
    "                    print(f\"Description: {table_info['description']}\")\n",
    "                    print(\"Relevant Columns:\")\n",
    "                    for col in table_info['columns']:\n",
    "                        print(f\"  - {col['name']} (Relevance: {col['relevance_score']:.3f}, Type: {col['data_type']})\")\n",
    "        else:\n",
    "            print(\"No relevant schema found\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

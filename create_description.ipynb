{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2e9a9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import Dict, List\n",
    "from model.load_model import description_agent\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51ddf4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def call_llm_agent(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Use the pydantic_ai agent to process the prompt and return a description.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Run the agent with the prompt\n",
    "        result = await description_agent.run(prompt)\n",
    "        return result.output\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling LLM agent: {str(e)}\")\n",
    "        # Fallback to mock implementation\n",
    "        table_name = prompt.split(\"Table: \")[1].split(\",\")[0]\n",
    "        return f\"This table stores and manages {table_name} related data with associated metadata and relationships.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcaa74d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def generate_table_description(table_name: str, columns: Dict, sample_data: List[Dict]) -> str:\n",
    "    \"\"\"\n",
    "    Generate a single description for the entire table using LLM agent.\n",
    "    \"\"\"\n",
    "    # Create column info string for context\n",
    "    column_info = []\n",
    "    for column_name, column_type in columns.items():\n",
    "        column_info.append(f\"{column_name} ({column_type})\")\n",
    "    \n",
    "    columns_str = \", \".join(column_info)\n",
    "    \n",
    "    # Create sample data string for context\n",
    "    sample_titles = []\n",
    "    for sample in sample_data[:3]:  # Use first 3 samples for context\n",
    "        # Try to find a descriptive field (title, name, etc.)\n",
    "        for field in ['title', 'name', 'description', 'label']:\n",
    "            if field in sample and sample[field]:\n",
    "                sample_titles.append(str(sample[field]))\n",
    "                break\n",
    "    \n",
    "    sample_str = \", \".join(sample_titles) if sample_titles else \"No sample data available\"\n",
    "    \n",
    "    prompt = f\"Table: {table_name}, Columns: {columns_str}, Sample Data: {sample_str}\"\n",
    "    \n",
    "    try:\n",
    "        description = await call_llm_agent(prompt)\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating description for {table_name}: {str(e)}\")\n",
    "        description = f\"This table stores and manages {table_name} related data with associated metadata and relationships.\"\n",
    "    \n",
    "    return description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26e60c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_schema_from_file(file_path: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Load schema from a Python file.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the schema Python file\n",
    "    \n",
    "    Returns:\n",
    "        dict: Schema dictionary or None if error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        spec = importlib.util.spec_from_file_location(\"schema_module\", file_path)\n",
    "        schema_module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(schema_module)\n",
    "        return schema_module.schema\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading schema from {file_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9380531",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_schema_for_file(schema: Dict, indent_level: int = 0) -> str:\n",
    "    \"\"\"\n",
    "    Format schema dictionary as a properly indented Python dictionary string\n",
    "    \"\"\"\n",
    "    if not schema:\n",
    "        return \"{}\"\n",
    "    \n",
    "    indent = \"    \" * indent_level\n",
    "    next_indent = \"    \" * (indent_level + 1)\n",
    "    \n",
    "    lines = [\"{\"]\n",
    "    \n",
    "    for key, value in schema.items():\n",
    "        if isinstance(value, dict):\n",
    "            # Handle nested dictionaries\n",
    "            formatted_value = format_schema_for_file(value, indent_level + 1)\n",
    "            lines.append(f'{next_indent}\"{key}\": {formatted_value},')\n",
    "        elif isinstance(value, list):\n",
    "            # Handle lists\n",
    "            if not value:\n",
    "                lines.append(f'{next_indent}\"{key}\": [],')\n",
    "            else:\n",
    "                lines.append(f'{next_indent}\"{key}\": [')\n",
    "                for item in value:\n",
    "                    if isinstance(item, dict):\n",
    "                        formatted_item = format_schema_for_file(item, indent_level + 2)\n",
    "                        lines.append(f'{next_indent}    {formatted_item},')\n",
    "                    else:\n",
    "                        lines.append(f'{next_indent}    {repr(item)},')\n",
    "                lines.append(f'{next_indent}],')\n",
    "        elif isinstance(value, str):\n",
    "            # Handle strings - escape quotes properly\n",
    "            escaped_value = value.replace('\"', '\\\\\"')\n",
    "            lines.append(f'{next_indent}\"{key}\": \"{escaped_value}\",')\n",
    "        else:\n",
    "            # Handle other types (int, float, bool, None)\n",
    "            lines.append(f'{next_indent}\"{key}\": {repr(value)},')\n",
    "    \n",
    "    lines.append(f\"{indent}}}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cd399aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_schema_to_file(file_path: str, schema: Dict):\n",
    "    \"\"\"\n",
    "    Write the updated schema with descriptions to a completely new Python file.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the schema Python file\n",
    "        schema (Dict): Updated schema dictionary containing descriptions\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Format the schema dictionary as a Python-compatible string\n",
    "        schema_str = format_schema_for_file(schema)\n",
    "        \n",
    "        # Create the complete file content\n",
    "        file_content = f\"schema = {schema_str}\\n\"\n",
    "        \n",
    "        # Delete the old file if it exists and write the new one\n",
    "        if os.path.exists(file_path):\n",
    "            os.remove(file_path)\n",
    "        \n",
    "        # Write the new file\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(file_content)\n",
    "            \n",
    "        print(f\"New schema file with descriptions created at {file_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error writing schema to {file_path}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab449ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def update_schema_with_descriptions(schema: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Update the schema dictionary to include a single description for each table.\n",
    "    \"\"\"\n",
    "    updated_schema = {}\n",
    "    \n",
    "    for table_name, table_info in schema.items():\n",
    "        print(f\"Processing table: {table_name}\")\n",
    "        \n",
    "        # Ensure table_info has the expected structure\n",
    "        if not isinstance(table_info, dict):\n",
    "            print(f\"Skipping {table_name}: invalid table structure\")\n",
    "            continue\n",
    "            \n",
    "        columns = table_info.get(\"columns\", {})\n",
    "        sample_data = table_info.get(\"sample\", [])\n",
    "        \n",
    "        # Generate description for this table\n",
    "        table_description = await generate_table_description(\n",
    "            table_name, \n",
    "            columns, \n",
    "            sample_data\n",
    "        )\n",
    "        \n",
    "        # Create updated table structure\n",
    "        updated_schema[table_name] = {\n",
    "            \"columns\": columns,\n",
    "            \"sample\": sample_data,\n",
    "            \"description\": table_description\n",
    "        }\n",
    "    \n",
    "    return updated_schema\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0893ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_database_files():\n",
    "    \"\"\"\n",
    "    Process all database schema files in the current directory\n",
    "    \"\"\"\n",
    "    # List of database files to process\n",
    "    db_files = [\"./schemas/chinook_db.py\", \"./schemas/netflix_db.py\"]\n",
    "    \n",
    "    for db_file in db_files:\n",
    "        if os.path.exists(db_file):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Processing {db_file}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            # Read schema from file\n",
    "            schema = read_schema_from_file(db_file)\n",
    "            \n",
    "            if schema:\n",
    "                # Clean the schema first to remove any malformed data\n",
    "                cleaned_schema = {}\n",
    "                for table_name, table_info in schema.items():\n",
    "                    if isinstance(table_info, dict) and \"columns\" in table_info:\n",
    "                        cleaned_schema[table_name] = {\n",
    "                            \"columns\": table_info.get(\"columns\", {}),\n",
    "                            \"sample\": table_info.get(\"sample\", [])\n",
    "                        }\n",
    "                \n",
    "                # Update schema with descriptions\n",
    "                updated_schema = await update_schema_with_descriptions(cleaned_schema)\n",
    "                \n",
    "                # Write back to file\n",
    "                write_schema_to_file(db_file, updated_schema)\n",
    "                \n",
    "                print(f\"\\nCompleted processing {db_file}\")\n",
    "                print(f\"Tables processed: {list(updated_schema.keys())}\")\n",
    "            else:\n",
    "                print(f\"No schema found in {db_file}\")\n",
    "        else:\n",
    "            print(f\"File {db_file} not found in current directory\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a0130d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "All database schema files have been processed!\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Processing ./schemas/chinook_db.py\n",
      "==================================================\n",
      "Processing table: Album\n",
      "Processing table: Artist\n",
      "Processing table: Customer\n",
      "Processing table: Employee\n",
      "Processing table: Genre\n",
      "Processing table: Invoice\n",
      "Processing table: InvoiceLine\n",
      "Processing table: MediaType\n",
      "Processing table: Playlist\n",
      "Processing table: PlaylistTrack\n",
      "Processing table: Track\n",
      "New schema file with descriptions created at ./schemas/chinook_db.py\n",
      "\n",
      "Completed processing ./schemas/chinook_db.py\n",
      "Tables processed: ['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n",
      "\n",
      "==================================================\n",
      "Processing ./schemas/netflix_db.py\n",
      "==================================================\n",
      "Processing table: movie\n",
      "Processing table: season\n",
      "Processing table: tv_show\n",
      "Processing table: view_summary\n",
      "New schema file with descriptions created at ./schemas/netflix_db.py\n",
      "\n",
      "Completed processing ./schemas/netflix_db.py\n",
      "Tables processed: ['movie', 'season', 'tv_show', 'view_summary']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import asyncio\n",
    "    \n",
    "    try:\n",
    "        # Try to get the running loop (if in async context)\n",
    "        loop = asyncio.get_running_loop()\n",
    "    except RuntimeError:  # No running loop\n",
    "        loop = None\n",
    "    \n",
    "    if loop:\n",
    "        # If in async context (like Jupyter), create a task\n",
    "        task = loop.create_task(process_database_files())\n",
    "        # In Jupyter you might want to await the task:\n",
    "        # await task  # (uncomment if in async context)\n",
    "    else:\n",
    "        # If not in async context, use asyncio.run()\n",
    "        asyncio.run(process_database_files())\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"All database schema files have been processed!\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24d751d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

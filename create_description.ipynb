{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2e9a9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "All database schema files have been processed!\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Processing ./schemas/chinook_db.py\n",
      "==================================================\n",
      "Processing table: Album\n",
      "Error calling LLM agent: status_code: 401, model_name: gpt-4.1, body: {'code': '401', 'message': 'Access denied due to invalid subscription key or wrong API endpoint. Make sure to provide a valid key for an active subscription and use a correct regional API endpoint for your resource.'}\n",
      "Processing table: Artist\n",
      "Error calling LLM agent: status_code: 401, model_name: gpt-4.1, body: {'code': '401', 'message': 'Access denied due to invalid subscription key or wrong API endpoint. Make sure to provide a valid key for an active subscription and use a correct regional API endpoint for your resource.'}\n",
      "Processing table: Customer\n",
      "Error calling LLM agent: status_code: 401, model_name: gpt-4.1, body: {'code': '401', 'message': 'Access denied due to invalid subscription key or wrong API endpoint. Make sure to provide a valid key for an active subscription and use a correct regional API endpoint for your resource.'}\n",
      "Processing table: Employee\n",
      "Error calling LLM agent: status_code: 401, model_name: gpt-4.1, body: {'code': '401', 'message': 'Access denied due to invalid subscription key or wrong API endpoint. Make sure to provide a valid key for an active subscription and use a correct regional API endpoint for your resource.'}\n",
      "Processing table: Genre\n",
      "Error calling LLM agent: status_code: 401, model_name: gpt-4.1, body: {'code': '401', 'message': 'Access denied due to invalid subscription key or wrong API endpoint. Make sure to provide a valid key for an active subscription and use a correct regional API endpoint for your resource.'}\n",
      "Processing table: Invoice\n",
      "Error calling LLM agent: status_code: 401, model_name: gpt-4.1, body: {'code': '401', 'message': 'Access denied due to invalid subscription key or wrong API endpoint. Make sure to provide a valid key for an active subscription and use a correct regional API endpoint for your resource.'}\n",
      "Processing table: InvoiceLine\n",
      "Error calling LLM agent: status_code: 401, model_name: gpt-4.1, body: {'code': '401', 'message': 'Access denied due to invalid subscription key or wrong API endpoint. Make sure to provide a valid key for an active subscription and use a correct regional API endpoint for your resource.'}\n",
      "Processing table: MediaType\n",
      "Error calling LLM agent: status_code: 401, model_name: gpt-4.1, body: {'code': '401', 'message': 'Access denied due to invalid subscription key or wrong API endpoint. Make sure to provide a valid key for an active subscription and use a correct regional API endpoint for your resource.'}\n",
      "Processing table: Playlist\n",
      "Error calling LLM agent: status_code: 401, model_name: gpt-4.1, body: {'code': '401', 'message': 'Access denied due to invalid subscription key or wrong API endpoint. Make sure to provide a valid key for an active subscription and use a correct regional API endpoint for your resource.'}\n",
      "Processing table: PlaylistTrack\n",
      "Error calling LLM agent: status_code: 401, model_name: gpt-4.1, body: {'code': '401', 'message': 'Access denied due to invalid subscription key or wrong API endpoint. Make sure to provide a valid key for an active subscription and use a correct regional API endpoint for your resource.'}\n",
      "Processing table: Track\n",
      "Error calling LLM agent: status_code: 401, model_name: gpt-4.1, body: {'code': '401', 'message': 'Access denied due to invalid subscription key or wrong API endpoint. Make sure to provide a valid key for an active subscription and use a correct regional API endpoint for your resource.'}\n",
      "Updated schema saved to ./schemas/chinook_db.py\n",
      "\n",
      "Completed processing ./schemas/chinook_db.py\n",
      "Tables processed: ['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n",
      "\n",
      "==================================================\n",
      "Processing ./schemas/netflix_db.py\n",
      "==================================================\n",
      "Processing table: movie\n",
      "Error calling LLM agent: status_code: 401, model_name: gpt-4.1, body: {'code': '401', 'message': 'Access denied due to invalid subscription key or wrong API endpoint. Make sure to provide a valid key for an active subscription and use a correct regional API endpoint for your resource.'}\n",
      "Processing table: season\n",
      "Error calling LLM agent: status_code: 401, model_name: gpt-4.1, body: {'code': '401', 'message': 'Access denied due to invalid subscription key or wrong API endpoint. Make sure to provide a valid key for an active subscription and use a correct regional API endpoint for your resource.'}\n",
      "Processing table: tv_show\n",
      "Error calling LLM agent: status_code: 401, model_name: gpt-4.1, body: {'code': '401', 'message': 'Access denied due to invalid subscription key or wrong API endpoint. Make sure to provide a valid key for an active subscription and use a correct regional API endpoint for your resource.'}\n",
      "Processing table: view_summary\n",
      "Error calling LLM agent: status_code: 401, model_name: gpt-4.1, body: {'code': '401', 'message': 'Access denied due to invalid subscription key or wrong API endpoint. Make sure to provide a valid key for an active subscription and use a correct regional API endpoint for your resource.'}\n",
      "Updated schema saved to ./schemas/netflix_db.py\n",
      "\n",
      "Completed processing ./schemas/netflix_db.py\n",
      "Tables processed: ['movie', 'season', 'tv_show', 'view_summary']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import Dict, List\n",
    "from model.load_model import description_agent\n",
    "import importlib\n",
    "\n",
    "\n",
    "async def call_llm_agent(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Use the pydantic_ai agent to process the prompt and return a description.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Run the agent with the prompt\n",
    "        result = await description_agent.run(prompt)\n",
    "        return result.data\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling LLM agent: {str(e)}\")\n",
    "        # Fallback to mock implementation\n",
    "        table_name = prompt.split(\"Table: \")[1].split(\",\")[0]\n",
    "        return f\"This table stores and manages {table_name} related data with associated metadata and relationships.\"\n",
    "\n",
    "async def generate_table_description(table_name: str, columns: List[Dict], sample_data: List[Dict]) -> str:\n",
    "    \"\"\"\n",
    "    Generate a single description for the entire table using LLM agent.\n",
    "    \"\"\"\n",
    "    # Create column info string for context\n",
    "    column_info = []\n",
    "    for column in columns:\n",
    "        column_name = list(column.keys())[0]\n",
    "        column_type = column[column_name]\n",
    "        column_info.append(f\"{column_name} ({column_type})\")\n",
    "    \n",
    "    columns_str = \", \".join(column_info)\n",
    "    \n",
    "    # Create sample data string for context\n",
    "    sample_titles = []\n",
    "    for sample in sample_data[:3]:  # Use first 3 samples for context\n",
    "        # Try to find a descriptive field (title, name, etc.)\n",
    "        for field in ['title', 'name', 'description', 'label']:\n",
    "            if field in sample and sample[field]:\n",
    "                sample_titles.append(str(sample[field]))\n",
    "                break\n",
    "    \n",
    "    sample_str = \", \".join(sample_titles) if sample_titles else \"No sample data available\"\n",
    "    \n",
    "    prompt = f\"Table: {table_name}, Columns: {columns_str}, Sample Data: {sample_str}\"\n",
    "    \n",
    "    try:\n",
    "        description = await call_llm_agent(prompt)\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating description for {table_name}: {str(e)}\")\n",
    "        description = f\"This table stores and manages {table_name} related data with associated metadata and relationships.\"\n",
    "    \n",
    "    return description\n",
    "\n",
    "def read_schema_from_file(file_path: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Load schema from a Python file.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the schema Python file\n",
    "    \n",
    "    Returns:\n",
    "        dict: Schema dictionary or None if error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        spec = importlib.util.spec_from_file_location(\"schema_module\", file_path)\n",
    "        schema_module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(schema_module)\n",
    "        return schema_module.schema\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading schema from {file_path}: {e}\")\n",
    "        return None\n",
    "    \n",
    "def write_schema_to_file(file_path: str, schema: Dict):\n",
    "    \"\"\"\n",
    "    Write the updated schema back to the Python file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the original file content\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Convert schema to a properly formatted string\n",
    "        schema_str = format_schema_for_file(schema)\n",
    "        \n",
    "        # Replace the schema definition\n",
    "        updated_content = re.sub(\n",
    "            r'schema\\s*=\\s*{.*?}',\n",
    "            f'schema = {schema_str}',\n",
    "            content,\n",
    "            flags=re.DOTALL\n",
    "        )\n",
    "        \n",
    "        # Write back to file\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(updated_content)\n",
    "            \n",
    "        print(f\"Updated schema saved to {file_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error writing schema to {file_path}: {str(e)}\")\n",
    "\n",
    "def format_schema_for_file(schema: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Format schema dictionary as a properly indented Python dictionary string\n",
    "    \"\"\"\n",
    "    def format_value(value, indent=0):\n",
    "        spaces = \"    \" * indent\n",
    "        if isinstance(value, dict):\n",
    "            if not value:\n",
    "                return \"{}\"\n",
    "            lines = [\"{\"]\n",
    "            for k, v in value.items():\n",
    "                formatted_v = format_value(v, indent + 1)\n",
    "                if isinstance(v, str):\n",
    "                    lines.append(f'{spaces}    \"{k}\": \"{formatted_v}\",')\n",
    "                else:\n",
    "                    lines.append(f'{spaces}    \"{k}\": {formatted_v},')\n",
    "            lines.append(f\"{spaces}}}\")\n",
    "            return \"\\n\".join(lines)\n",
    "        elif isinstance(value, list):\n",
    "            if not value:\n",
    "                return \"[]\"\n",
    "            lines = [\"[\"]\n",
    "            for item in value:\n",
    "                formatted_item = format_value(item, indent + 1)\n",
    "                lines.append(f\"{spaces}    {formatted_item},\")\n",
    "            lines.append(f\"{spaces}]\")\n",
    "            return \"\\n\".join(lines)\n",
    "        elif isinstance(value, str):\n",
    "            return value\n",
    "        else:\n",
    "            return repr(value)\n",
    "    \n",
    "    return format_value(schema)\n",
    "\n",
    "async def update_schema_with_descriptions(schema: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Update the schema dictionary to include a single description for each table.\n",
    "    \"\"\"\n",
    "    updated_schema = {}\n",
    "    \n",
    "    for table_name, table_info in schema.items():\n",
    "        print(f\"Processing table: {table_name}\")\n",
    "        \n",
    "        # Generate description for this table\n",
    "        table_description = await generate_table_description(\n",
    "            table_name, \n",
    "            table_info[\"columns\"], \n",
    "            table_info[\"sample\"]\n",
    "        )\n",
    "        \n",
    "        # Create updated table structure with original column format\n",
    "        columns = {}\n",
    "        for column in table_info[\"columns\"]:\n",
    "            column_name = list(column.keys())[0]\n",
    "            column_type = column[column_name]\n",
    "            columns[column_name] = column_type\n",
    "        \n",
    "        updated_schema[table_name] = {\n",
    "            \"columns\": columns,\n",
    "            \"sample\": table_info[\"sample\"],\n",
    "            \"description\": table_description\n",
    "        }\n",
    "    \n",
    "    return updated_schema\n",
    "\n",
    "async def process_database_files():\n",
    "    \"\"\"\n",
    "    Process all database schema files in the current directory\n",
    "    \"\"\"\n",
    "    # List of database files to process\n",
    "    db_files = [\"./schemas/chinook_db.py\", \"./schemas/netflix_db.py\"]\n",
    "    \n",
    "    for db_file in db_files:\n",
    "        if os.path.exists(db_file):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Processing {db_file}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            # Read schema from file\n",
    "            schema = read_schema_from_file(db_file)\n",
    "            \n",
    "            if schema:\n",
    "                # Update schema with descriptions\n",
    "                updated_schema = await update_schema_with_descriptions(schema)\n",
    "                \n",
    "                # Write back to file\n",
    "                write_schema_to_file(db_file, updated_schema)\n",
    "                \n",
    "                print(f\"\\nCompleted processing {db_file}\")\n",
    "                print(f\"Tables processed: {list(updated_schema.keys())}\")\n",
    "            else:\n",
    "                print(f\"No schema found in {db_file}\")\n",
    "        else:\n",
    "            print(f\"File {db_file} not found in current directory\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import asyncio\n",
    "    \n",
    "    try:\n",
    "        # Try to get the running loop (if in async context)\n",
    "        loop = asyncio.get_running_loop()\n",
    "    except RuntimeError:  # No running loop\n",
    "        loop = None\n",
    "    \n",
    "    if loop:\n",
    "        # If in async context (like Jupyter), create a task\n",
    "        task = loop.create_task(process_database_files())\n",
    "        # In Jupyter you might want to await the task:\n",
    "        # await task  # (uncomment if in async context)\n",
    "    else:\n",
    "        # If not in async context, use asyncio.run()\n",
    "        asyncio.run(process_database_files())\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"All database schema files have been processed!\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf23109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a0130d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

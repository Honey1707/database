{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c75ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f50878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_schema_from_file(schema_file_path):\n",
    "    \"\"\"\n",
    "    Load schema from a Python file.\n",
    "    \n",
    "    Args:\n",
    "        schema_file_path (str): Path to the schema Python file\n",
    "    \n",
    "    Returns:\n",
    "        dict: Schema dictionary or None if error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        spec = importlib.util.spec_from_file_location(\"schema_module\", schema_file_path)\n",
    "        schema_module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(schema_module)\n",
    "        return schema_module.schema\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading schema from {schema_file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa527e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sample_data(db_path, table_name, limit=5):\n",
    "    \"\"\"\n",
    "    Extract sample data from a table, prioritizing rows with no null values.\n",
    "    \n",
    "    Args:\n",
    "        db_path (str): Path to the database file\n",
    "        table_name (str): Name of the table\n",
    "        limit (int): Number of rows to extract (default: 5)\n",
    "    \n",
    "    Returns:\n",
    "        list: List of dictionaries representing rows\n",
    "    \"\"\"\n",
    "    try:\n",
    "        engine = create_engine(f'sqlite:///{db_path}')\n",
    "        \n",
    "        # First, try to get rows with no null values\n",
    "        query_no_nulls = f\"\"\"\n",
    "        SELECT * FROM {table_name} \n",
    "        WHERE {' AND '.join([f'{col} IS NOT NULL' for col in get_table_columns(db_path, table_name)])}\n",
    "        LIMIT {limit}\n",
    "        \"\"\"\n",
    "        \n",
    "        with engine.connect() as conn:\n",
    "            try:\n",
    "                result = conn.execute(text(query_no_nulls))\n",
    "                rows = result.fetchall()\n",
    "                columns = result.keys()\n",
    "                \n",
    "                # If we don't have enough rows without nulls, get any rows\n",
    "                if len(rows) < limit:\n",
    "                    query_any = f\"SELECT * FROM {table_name} LIMIT {limit}\"\n",
    "                    result = conn.execute(text(query_any))\n",
    "                    rows = result.fetchall()\n",
    "                    columns = result.keys()\n",
    "                \n",
    "                # Convert to list of dictionaries\n",
    "                sample_data = []\n",
    "                for row in rows:\n",
    "                    row_dict = {}\n",
    "                    for i, col in enumerate(columns):\n",
    "                        row_dict[col] = row[i]\n",
    "                    sample_data.append(row_dict)\n",
    "                \n",
    "                return sample_data\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error querying table {table_name}: {e}\")\n",
    "                return []\n",
    "                \n",
    "    except SQLAlchemyError as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba636d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_columns(db_path, table_name):\n",
    "    \"\"\"\n",
    "    Get column names for a table.\n",
    "    \n",
    "    Args:\n",
    "        db_path (str): Path to the database file\n",
    "        table_name (str): Name of the table\n",
    "    \n",
    "    Returns:\n",
    "        list: List of column names\n",
    "    \"\"\"\n",
    "    try:\n",
    "        engine = create_engine(f'sqlite:///{db_path}')\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(text(f\"PRAGMA table_info({table_name})\"))\n",
    "            columns = [row[1] for row in result.fetchall()]  # Column name is at index 1\n",
    "            return columns\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting columns for {table_name}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6409ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_samples_to_schema(schema_folder=\"schemas\", database_folder=\"database\"):\n",
    "    \"\"\"\n",
    "    Find schema files, extract sample data, and add samples to schema.\n",
    "    \n",
    "    Args:\n",
    "        schema_folder (str): Folder containing schema Python files\n",
    "        database_folder (str): Folder containing database files\n",
    "    \n",
    "    Returns:\n",
    "        dict: Updated schemas with sample data\n",
    "    \"\"\"\n",
    "    \n",
    "    schema_files = list(Path(schema_folder).glob(\"*.py\"))\n",
    "    \n",
    "    if not schema_files:\n",
    "        print(f\"No schema files found in {schema_folder}\")\n",
    "        return {}\n",
    "    \n",
    "    updated_schemas = {}\n",
    "    \n",
    "    for schema_file in schema_files:\n",
    "        print(f\"\\nProcessing {schema_file.name}...\")\n",
    "        \n",
    "        # Load schema from file\n",
    "        schema = load_schema_from_file(str(schema_file))\n",
    "        if not schema:\n",
    "            continue\n",
    "        \n",
    "        # Extract database name from schema file name\n",
    "        # Remove .py extension and _db suffix if present\n",
    "        db_name = schema_file.stem\n",
    "        if db_name.endswith('_db'):\n",
    "            db_name = db_name[:-3]  # Remove '_db'\n",
    "        \n",
    "        # Look for corresponding database file\n",
    "        db_path = Path(database_folder) / f\"{db_name}.db\"\n",
    "        \n",
    "        if not db_path.exists():\n",
    "            print(f\"Database file not found: {db_path}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Found database: {db_path}\")\n",
    "        \n",
    "        # Add sample data to each table in schema\n",
    "        updated_schema = {}\n",
    "        for table_name, columns in schema.items():\n",
    "            print(f\"  Extracting samples from table: {table_name}\")\n",
    "            \n",
    "            # Extract sample data\n",
    "            sample_data = extract_sample_data(str(db_path), table_name, limit=5)\n",
    "            \n",
    "            # Add to schema\n",
    "            updated_schema[table_name] = {\n",
    "                \"columns\": columns,\n",
    "                \"sample\": sample_data\n",
    "            }\n",
    "        \n",
    "        # Save updated schema back to file\n",
    "        output_file = schema_file\n",
    "        with open(output_file, 'w') as f:\n",
    "            f.write(f\"# Database schema for {db_name}.db\\n\")\n",
    "            f.write(f\"# Generated automatically with sample data\\n\\n\")\n",
    "            f.write(f\"schema = {json.dumps(updated_schema, indent=4, default=str)}\\n\")\n",
    "        \n",
    "        updated_schemas[db_name] = updated_schema\n",
    "        print(f\"  Updated schema saved to: {output_file}\")\n",
    "    \n",
    "    return updated_schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd43e2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_schema(schema_file_path, database_folder=\"database\"):\n",
    "    \"\"\"\n",
    "    Process a single schema file and add sample data.\n",
    "    \n",
    "    Args:\n",
    "        schema_file_path (str): Path to the schema file\n",
    "        database_folder (str): Folder containing database files\n",
    "    \n",
    "    Returns:\n",
    "        dict: Updated schema with sample data\n",
    "    \"\"\"\n",
    "    \n",
    "    schema_file = Path(schema_file_path)\n",
    "    \n",
    "    if not schema_file.exists():\n",
    "        print(f\"Schema file not found: {schema_file_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Processing {schema_file.name}...\")\n",
    "    \n",
    "    # Load schema from file\n",
    "    schema = load_schema_from_file(str(schema_file))\n",
    "    if not schema:\n",
    "        return None\n",
    "    \n",
    "    # Extract database name from schema file name\n",
    "    db_name = schema_file.stem\n",
    "    if db_name.endswith('_db'):\n",
    "        db_name = db_name[:-3]  # Remove '_db'\n",
    "    \n",
    "    # Look for corresponding database file\n",
    "    db_path = Path(database_folder) / f\"{db_name}.db\"\n",
    "    \n",
    "    if not db_path.exists():\n",
    "        print(f\"Database file not found: {db_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Found database: {db_path}\")\n",
    "    \n",
    "    # Add sample data to each table in schema\n",
    "    updated_schema = {}\n",
    "    for table_name, columns in schema.items():\n",
    "        print(f\"  Extracting samples from table: {table_name}\")\n",
    "        \n",
    "        # Extract sample data\n",
    "        sample_data = extract_sample_data(str(db_path), table_name, limit=5)\n",
    "        \n",
    "        # Add to schema\n",
    "        updated_schema[table_name] = {\n",
    "            \"columns\": columns,\n",
    "            \"sample\": sample_data\n",
    "        }\n",
    "    \n",
    "    # Save updated schema back to file\n",
    "    with open(schema_file, 'w') as f:\n",
    "        f.write(f\"# Database schema for {db_name}.db\\n\")\n",
    "        f.write(f\"# Generated automatically with sample data\\n\\n\")\n",
    "        f.write(f\"schema = {json.dumps(updated_schema, indent=4, default=str)}\\n\")\n",
    "    \n",
    "    print(f\"Updated schema saved to: {schema_file}\")\n",
    "    return updated_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c9ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Process all schema files in schemas folder\n",
    "    updated_schemas = add_samples_to_schema(\"schemas\", \"database\")\n",
    "    \n",
    "    # Or process a single schema file\n",
    "    # updated_schema = process_single_schema(\"schemas/chinook.py\", \"database\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nProcessed {len(updated_schemas)} schemas:\")\n",
    "    for db_name, schema in updated_schemas.items():\n",
    "        print(f\"  {db_name}: {len(schema)} tables\")\n",
    "        for table_name, table_info in schema.items():\n",
    "            sample_count = len(table_info.get('sample', []))\n",
    "            print(f\"    - {table_name}: {sample_count} sample rows\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
